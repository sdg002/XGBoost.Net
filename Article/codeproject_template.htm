<!DOCTYPE HTML>
<!--------------------------------------------------------------------------->  
<!--                           INTRODUCTION                                

 The CodeProject article submission template (HTML version)

Using this template will help us post your article sooner. To use, just 
follow the 3 easy steps below:
 
     1. Fill in the article description details
     2. Add links to your images and downloads
     3. Include the main article text

That's all there is to it! All formatting will be done by our submission
scripts and style sheets. 

-->  
<!--------------------------------------------------------------------------->  
<!--                        IGNORE THIS SECTION                            -->
<html>
<head>
<title>CodeProject</title>
<Style>
BODY, P, TD { font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 10pt }
H2,H3,H4,H5 { color: #ff9900; font-weight: bold; }
H2 { font-size: 13pt; }
H3 { font-size: 12pt; }
H4 { font-size: 10pt; color: black; }
PRE { BACKGROUND-COLOR: #FBEDBB; FONT-FAMILY: "Courier New", Courier, mono; WHITE-SPACE: pre; }
CODE { COLOR: #990000; FONT-FAMILY: "Courier New", Courier, mono; }
</style>
<link type="text/css" rel="stylesheet" 
      href="https://codeproject.global.ssl.fastly.net/App_Themes/CodeProject/Css/Main.min.css">
</head>
<body bgcolor="#FFFFFF" color=#000000>
<!--------------------------------------------------------------------------->  


<!-------------------------------     STEP 1      --------------------------->
<!--  Fill in the details (CodeProject will reformat this section for you) -->

<pre>
Title:       Enter Article Title Here
Author:      Enter your Code Project User Name (or suggest one if you're not a member)
Email:       Enter your Code Project E-mail Login (or the email you wish to use if not a member)
Language:    Enter the Languages that Apply to Your Article (C# 3.0, etc.)
Platform:    Enter the Platforms that Apply to Your Article (Windows, etc.)
Technology:  Enter the Technologies that Apply to Your Article (WPF, etc.)
Level:       Pick ONE: Beginner/Intermediate/Advanced
Description: Enter a brief description of your article
Section      Enter the Code Project Section you Wish the Article to Appear
SubSection   Enter the Code Project SubSection you Wish the Article to Appear
License:     Enter the license (<a href="http://www.codeproject.com/info/licenses.aspx">CPOL, CPL, MIT, etc</a>)
</pre>

<!-------------------------------     STEP 2      --------------------------->
<!--  Include download and sample image information.                       --> 

<ul class=download>
<li><a href="Article_demo.zip">Download demo project - XXX Kb </a></li>
<li><a href="Article_src.zip">Download source - XXX Kb</a></li>
</ul>

<p><img 
        src="images/WikiImages.png" 
        alt="Sample Image - maximum width is 600 pixels" 
        style="width:400px; height:200px"></p>
    <i>Image source:Wikipedia</i>
<p>
    
</p>

<!-------------------------------     STEP 3      --------------------------->

<!--  Add the article text. Please use simple formatting (<h2>, <p> etc)   -->

<h2 id="toc">Table of contents</h2>
    <ul>
        <li><a href="#intro">Introduction</a></li>
        <li><a href="#background">Background</a></li>
        <li><a href="#overview_gradient_boost">Overview of Gradient Boost Classification algorithm</a></li>
        <li>
            <ul>
                <li>
                    <a href="#overview_gradient_boost_decisiontree">Intro to decision trees (StatQuest)</a></li>
                <li>
                    <a href="#overview_gradient_boost_giniindex">Understanding Gini index while constructing a decision tree</a>
                </li>
                <li>
                    <a href="#overview_gradient_boost_adaboost">Intro to AdaBoost</a>
                </li>
                <li>
                    <a href="#overview_gradient_boost_gradboost">Intro to Gradient Boost</a>
                </li>
            </ul>
        </li>
        <li><a href="#xgboostlib">XGBoost library(C#)</a></li>
        <li>
            <ul>
                <li><a href="#xgboostlib_overview">Overview</a></li>
                <li><a href="#xgboostlib_managedwrapper">Managed wrapper</a></li>
                <li><a href="#xgboostlib_simplelinear">Simple linear classification problem</a></li>
                <li><a href="#xgboostlib_xor">Implementing XOR logic</a></li>
                <li><a href="#xgboostlib_savemodel">Persisting a model to file</a></li>
            </ul>
        </li>
        <li><a href="#iris">Iris dataset</a></li>
        <li>
            <ul>
                <li><a href="#iris_overview">Overview</a></li>
                <li><a href="#iris_datastructure">Data structure</a></li>
                <li><a href="#iris_parsing">Parsing IRIS records from CSV</a></li>
                <li><a href="#iris_vector">Creating a feature vector from CSV</a></li>
                <li><a href="#iris_loading_putting_all_together">Loading IRIS-putting it all together</a></li>
                <li><a href="#iris_train_test">Training and testing IRIS</a></li>
            </ul>
        </li>
        <li><a href="#using_the_code">Using the code</a></li>
        <li>
            <ul>
                <li><a href="#using_the_code_github">Github</a></li>
                <li><a href="#using_the_code_soln">Solution structure</a></li>
            </ul>
        </li>
        <li><a href="#">TO BE DONE</a></li>
        <li><a href="#">TO BE DONE</a></li>
    </ul>
<h2 id="intro">Introduction</h2>
<p>In this article I have demonstrated how to use the <a href="https://github.com/PicNet/XGBoost.Net"><strong>C# wrapper of the popular</strong></a> XGBoost unmanaged library. <a href="https://xgboost.readthedocs.io/en/latest/index.html"><strong>XGBoost</strong></a> stands for "Extreme Gradient Boosting".
    I  have used the famous <strong><a href="#iris">IRIS</a></strong> dataset to train and test a model. My objective was to share my learnings of how to embed a machine learning algorithm like extreme gradient boosting
    in your C# application. Before I move forward I must extend my gratitude to the developers of the XGBoost unmanaged library and to the developers of .NET wrapper library.
</p>
<a href="#toc" title="Table of contents">top</a>

<h2 id="background">Background</h2>
<p>
    This article expects the user to be comfortable with an intermediate knowledge of the following:
</p>
<ul>
    <li>Decision tree algorithm</li>
    <li>Gradient boosting algorithm</li>
    <li>Data normalization</li>
    <li>C#</li>
</ul>
    
 <p>
    This article and the accompanying code refrains from providing an indepth tutorial
    of decision trees and gradient boosting algorithms.
</p>
<a href="#toc" title="Table of contents">top</a>


<h2 id="overview_gradient_boost">Overview of Gradient Boost Classification algorithm</h2>
<h3 id="overview_gradient_boost_decisiontree">Intro to decision trees (StatQuest)</h3>
<p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/7VeUPuFGJHk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
<a href="#toc" title="Table of contents">top</a>
<h3 id="overview_gradient_boost_giniindex">Understanding Gini index while constructing a decision tree</h3>
<p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/Zze7SKuz9QQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
<a href="#toc" title="Table of contents">top</a>
<h3 id="overview_gradient_boost_adaboost">Intro to AdaBoost</h3>
<p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/LsK-xG1cLYA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
<a href="#toc" title="Table of contents">top</a>
<h3 id="overview_gradient_boost_gradboost">Intro to Gradient Boost</h3>
<p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/3CC4N4z3GJc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
<a href="#toc" title="Table of contents">top</a>

<h2 id="xgboostlib">XGBoost library (C#)</h2>

<h3 id="xgboostlib_managedwrapper">Managed wrapper</h3>
<p>
    The C/C++ source code for the original XGBoost library is available on <strong><a href="https://github.com/dmlc/xgboost">Github</a></strong>. You can find build instructions for Windows.
    Thanks to the efforts of <strong><a href="https://github.com/PicNet/XGBoost.Net">PicNet</a></strong>, we can skip the step of compiling the unmanaged sources and directly jump to the managed wrapper.
</p>
<a href="#toc" title="Table of contents">top</a>

<h3 id="xgboostlib_simplelinear">Simple linear classification problem (YOU WERE HERE, write source code in new unit test)</h3>
<img src="images/LinearClass.svg" />
<p>We will carry out a simple exercise where we will train a model to class 2 clusters of points which are nicely linearly separable</p>
<pre>
        /// &lt;summary&gt;
        /// Two classes of vectors - Class-Blue and Class-Red
        /// Class-Blue  - The vectors are centered around the point (+0.5,+0.5) and label value=1
        /// Class-Red   - The vectors are centered around the point (-0.5,-0.5) and label value=0
        /// &lt;summary&gt;
        [TestMethod]
        public void LinearClassification1()
        {
            var xgb = new XGBoost.XGBClassifier();
            float[][] vectorsTrain = new float[][]
            {
                new[] {0.5f,0.5f},
                new[] {0.6f,0.6f},
                new[] {0.6f,0.4f},
                new[] {0.4f,0.6f},
                new[] {0.4f,0.4f},

                new[] {-0.5f,-0.5f},
                new[] {-0.6f,-0.6f},
                new[] {-0.6f,-0.4f},
                new[] {-0.4f,-0.6f},
                new[] {-0.4f,-0.4f},
            };
            var lablesTrain = new[]
            {
                1.0f,
                1.0f,
                1.0f,
                1.0f,
                1.0f,

                0.0f,
                0.0f,
                0.0f,
                0.0f,
                0.0f,
            };
            ///
            /// Ensure count of training labels=count of training vectors
            ///
            Assert.AreEqual(vectorsTrain.Length, lablesTrain.Length);
            ///
            /// Train the model
            ///
            xgb.Fit(vectorsTrain, lablesTrain);
            ///
            /// Test the model using test vectors
            ///
            float[][] vectorsTest = new float[][]
            {
                new[] {0.55f,0.55f},
                new[] {0.55f,0.45f},
                new[] {0.45f,0.55f},
                new[] {0.45f,0.45f},

                new[] {-0.55f,-0.55f},
                new[] {-0.55f,-0.45f},
                new[] {-0.45f,-0.55f},
                new[] {-0.45f,-0.45f},
            };
            var labelsTestExpected = new[]
            {
                1.0f,
                1.0f,
                1.0f,
                1.0f,

                0.0f,
                0.0f,
                0.0f,
                0.0f,
            };
            float[] labelsTestPredicted = xgb.Predict(vectorsTest);
            ///
            /// Verify that predicted labels match the expected labels
            ///
            CollectionAssert.AreEqual(labelsTestPredicted, labelsTestExpected);
        }

</pre>
<a href="#toc" title="Table of contents">top</a>

<h3 id="xgboostlib_xor">Implementing XOR logic</h3>
<p>
    The XOR logic is more complex than the a linear classification. The data points are not directly linearly separable.
    <br />
    <img src="images/XOR.svg" />
    <br />    
</p>

    <h4>XOR Truth table</h4>
    <pre>
        X | Y | OUTPUT
        --------------
        1 | 0 |   1
        --------------
        0 | 1 |   1
        --------------
        0 | 0 |   0
        --------------
        1 | 1 |   0
        --------------
        
    </pre>

    <h4>Sample code</h4>
    <pre>
        [TestMethod]
        public void TestMethod1()
        {
            var xgb = new XGBoost.XGBClassifier();
            ///
            /// Generate training vectors
            ///
            int countTrainingPoints = 50;
            entity.XGBArray trainClass_0_1 = Util.GenerateRandom2dPoints(countTrainingPoints / 2, 
                0.0, 0.5,
                0.5, 1.0, 1.0);//0,1
            entity.XGBArray trainClass_1_0 = Util.GenerateRandom2dPoints(countTrainingPoints / 2,
                0.5, 1.0,
                0.0, 0.5, 1.0);//1,0
            entity.XGBArray trainClass_0_0 = Util.GenerateRandom2dPoints(countTrainingPoints / 2,
                0.0, 0.5,
                0.0, 0.5, 0.0);//0,0
            entity.XGBArray trainClass_1_1 = Util.GenerateRandom2dPoints(countTrainingPoints / 2,
                0.5, 1.0,
                0.5, 1.0, 0.0);//1,1
            ///
            /// Train the model
            ///
            entity.XGBArray allVectorsTraining = Util.UnionOfXGBArrays(trainClass_0_1,trainClass_1_0,trainClass_0_0,trainClass_1_1);
            xgb.Fit(allVectorsTraining.Vectors, allVectorsTraining.Labels);
            ///
            /// Test the model
            ///
            int countTestingPoints = 10;
            entity.XGBArray testClass_0_1 = Util.GenerateRandom2dPoints(countTestingPoints ,
                0.1, 0.4,
                0.6, 0.9, 1.0);//0,1
            entity.XGBArray testClass_1_0 = Util.GenerateRandom2dPoints(countTestingPoints,
                0.6, 0.9,
                0.1, 0.4, 1.0);//1,0
            entity.XGBArray testClass_0_0 = Util.GenerateRandom2dPoints(countTestingPoints,
                0.1, 0.4,
                0.1, 0.4, 0.0);//0,0
            entity.XGBArray testClass_1_1 = Util.GenerateRandom2dPoints(countTestingPoints,
                0.6, 0.9,
                0.6, 0.9, 0.0);//1,1
            entity.XGBArray allVectorsTest = Util.UnionOfXGBArrays(testClass_0_1, testClass_1_0,testClass_0_0,testClass_1_1);
            var resultsActual = xgb.Predict(allVectorsTest.Vectors);
            CollectionAssert.AreEqual(resultsActual, allVectorsTest.Labels);

        }
    </pre>
<a href="#toc" title="Table of contents">top</a>
    <h3 id="xgboostlib_savemodel">Persisting a model to file</h3>
    <p>Once a model has been trained and found to produce satisfactory results, you would like to use this model in production.
        The method <strong>SaveModelToFile</strong> will persist the model to a binary file. The static method <strong>LoadClassifierFromFile</strong> will rehydrate
        the saved model.
    </p>
    <pre>
        var xgbTrainer = new XGBoost.XGBClassifier();
        ///
        ///Train the model
        ///
        xgbTrainer.SaveModelToFile("SimpleLinearClassifier.dat");
        ///
        ///Load the persisted model
        ///
        var xgbProduction = XGBoost.XGBClassifier.LoadClassifierFromFile(fileModel);
    </pre>

<h2 id="iris">Iris dataset (you were here)</h2>
<h3 id="iris_overview">Overview</h3>
<p>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/330px-Kosaciec_szczecinkowaty_Iris_setosa.jpg"/>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/330px-Iris_versicolor_3.jpg"/>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/330px-Iris_virginica.jpg" />
    <br />
    <i>Source:Wikipedia</i>
    <br />

    The data set contains 50 records from each of the three species of the Iris flower. This data set is a test case to 
    demonstrate many statistical classification techniques. <b>Describe the columns</b>

</p>
    <ol>
        <li>Iris-setosa</li>
        <li>Iris-versicolor</li>
        <li>Iris-virginica</li>
    </ol>

<a href="#toc" title="Table of contents">top</a>

<h3 id="iris_datastructure">Data structure</h3>
<p>
    <img src="images/Iris_Data_Snapshot.PNG"/>
    <br />
    <i>Source: Wikipedia</i>

</p>
<a href="#toc" title="Table of contents">top</a>

<h3 id="iris_parsing">Parsing IRIS records from CSV</h3>
<pre>
    ///
    ///The C# class Iris will be used for capturing a single data row
    ///
    public class Iris
    {
        public float Col1 { get; set; }
        public float Col2 { get; set; }
        public float Col3 { get; set; }
        public float Col4 { get; set; }
        public string Petal { get; set; }
    }
    ///
    ///The function LoadIris will read the specified file line by line and create an instance of the Iris POCO
    ///The class TextFieldParser from the assembly Microsoft.VisualBasic is being used here
    ///
    private Iris[] LoadIris(string filename)
    {
        string pathFull = System.IO.Path.Combine(Util.GetProjectDir2(), filename);
        List&lt;Iris&gt; records = new List&lt;Iris&gt;();
        using (var parser = new TextFieldParser(pathFull))
        {
            parser.TextFieldType = FieldType.Delimited;
            parser.SetDelimiters(",");
            while (!parser.EndOfData)
            {
                var fields = parser.ReadFields();
                Iris oRecord = new Iris();
                oRecord.Col1 = float.Parse(fields[0]);
                oRecord.Col2 = float.Parse(fields[1]);
                oRecord.Col3 = float.Parse(fields[2]);
                oRecord.Col4 = float.Parse(fields[3]);
                oRecord.Petal = fields[4];
                records.Add(oRecord);
            }
        }
</pre>
<a href="#toc" title="Table of contents">top</a>
<h3 id="iris_vector">Creating a feature vector from CSV</h3>
<pre>
        /// &lt;summary&gt;
        /// Create XGBoost consumable feature vector from Iris POCO classes
        /// &lt;/summary&gt;
        internal static XGVector&lt;Iris&gt;[] ConvertFromIrisToFeatureVectors(Iris[] records)
        {
            List&lt;XGVector&lt;Iris&gt;&gt; vectors = new List&lt;XGVector&lt;Iris&gt;&gt;();
            foreach (var rec in records)
            {
                XGVector&lt;Iris&gt; newVector = new XGVector&lt;Iris&gt;();
                newVector.Original = rec;
                newVector.Features = new float[]
                {
                    rec.Col1, rec.Col2,rec.Col3,rec.Col4
                };
                newVector.Label = ConvertLabelFromStringToNumeric(rec.Petal);
                vectors.Add(newVector);
            }
            return vectors.ToArray();
        }


        /// &lt;summary&gt;
        /// Converts the string based name of the petal to a numeric representation
        /// &lt;/summary&gt;
        internal static float ConvertLabelFromStringToNumeric(string petal)
        {
            if (petal.Contains("setosa"))
            {
                return 0;
            }
            else if (petal.Contains("versicolor"))
            {
                return 1.0f;
            }
            else if (petal.Contains("virginica"))
            {
                return 2.0f;
            }
            else
            {
                throw new NotImplementedException();
            }
        }
</pre>
<a href="#toc" title="Table of contents">top</a>

<h3 id="iris_loading_putting_all_together">Loading IRIS-putting it all together</h3>
<pre>
        [TestMethod]
        public void BasicLoadData()
        {
            string filename = "Iris\\Iris.train.data";
            iris.Iris[] records = IrisUtils.LoadIris(filename);
            entity.XGVector&lt;iris.Iris&gt;[] vectors = IrisUtils.ConvertFromIrisToFeatureVectors(records);
            Assert.IsTrue(records.Length &gt;= 140);
        }

</pre>
<a href="#toc" title="Table of contents">top</a>

<h3 id="iris_train_test">Training and testing IRIS</h3>
<pre>
        [TestMethod]
        public void TrainAndTestIris()
        {
            ///
            /// Load training vectors
            ///
            string filenameTrain = "Iris\\Iris.train.data";
            iris.Iris[] recordsTrain = IrisUtils.LoadIris(filenameTrain);
            entity.XGVector&lt;iris.Iris&gt;[] vectorsTrain = IrisUtils.ConvertFromIrisToFeatureVectors(recordsTrain);
            ///
            /// Load testingvectors
            ///
            string filenameTest = "Iris\\Iris.test.data";
            iris.Iris[] recordsTest = IrisUtils.LoadIris(filenameTest);
            entity.XGVector&lt;iris.Iris&gt;[] vectorsTest = IrisUtils.ConvertFromIrisToFeatureVectors(recordsTest);

            int noOfClasses = 3;
            var xgbc = new XGBoost.XGBClassifier(objective: "multi:softprob", numClass:3);
            entity.XGBArray arrTrain = Util.ConvertToXGBArray(vectorsTrain);
            entity.XGBArray arrTest = Util.ConvertToXGBArray(vectorsTest);
            xgbc.Fit(arrTrain.Vectors, arrTrain.Labels);
            var outcomeTest=xgbc.Predict(arrTest.Vectors);
            for(int index=0;index&lt;arrTest.Vectors.Length;index++)
            {
                string sExpected = IrisUtils.ConvertLabelFromNumericToString(arrTest.Labels[index]);
                float[] arrResults = new float[]
                {
                    outcomeTest[index*noOfClasses +0],
                    outcomeTest[index*noOfClasses +1],
                    outcomeTest[index*noOfClasses +2]
                };
                float max = arrResults.Max();
                int indexWithMaxValue = Util.GetIndexWithMaxValue(arrResults);
                string sActualClass = IrisUtils.ConvertLabelFromNumericToString((float)indexWithMaxValue);
                Trace.WriteLine($"{index}       Expected={sExpected}        Actual={sActualClass}");
                Assert.AreEqual(sActualClass, sExpected);
            }
            string pathFull = System.IO.Path.Combine(Util.GetProjectDir2(), _fileModelIris);
            xgbc.SaveModelToFile(pathFull);
        }
</pre>
<a href="#toc" title="Table of contents">top</a>



<h2 id="using_the_code">Using the code</h2>
    <h3 id="using_the_code_github">Github</h3>
    <ul class="download">
	    <li><a href="https://github.com/sdg002/XGBoost.Net">https://github.com/sdg002/XGBoost.Net</a></li>
    </ul>
    <h3 id="using_the_code_soln">Solution structure</h3>
    <pre>
        |
        |-----XGBoost
        |
        |-----XGBoostTests
        |           |
        |           |---iris
        |           |     |
        |           |     |--Iris.data
        |           |     |
        |           |     |--Iris.test.data
        |           |     |
        |           |     |--Iris.train.data
        |           |     |
        |           |     |--Iris.cs
        |           |     |
        |           |     
        |           |---IrisUtils.cs
        |           |
        |           |---IrisUnitTest.cs
        |           |
        |           |---SimpleLinearClassifierTests.cs
        |           |
        |           |---XORClassifierTests.cs
        |           |
        |
        |
    </pre>
    <a href="#toc" title="Table of contents">top</a>
<hr />




<!-------------------------------    That's it!   --------------------------->
</body>

</html>

